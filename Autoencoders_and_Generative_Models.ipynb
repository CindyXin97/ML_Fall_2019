{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{\\tp}{\\mathbf{{(t)}}}\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro `_latex_std_` created. To execute, type its name (without quotes).\n",
      "=== Macro contents: ===\n",
      "get_ipython().run_line_magic('run', 'Latex_macros.ipynb')\n",
      " "
     ]
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYek5uDM0gmo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AutoEncoders\n",
    "\n",
    "\n",
    "\n",
    "We revisit Unsupervised Learning, this time in a Deep Learning genre via Autoencoders\n",
    "- understand representations\n",
    "- unsupervised pretraining\n",
    "    - manifold hypothesis: for a supervised problem, two near-by inputs have the same output\n",
    "    - AE learns groups of near-by (in input space)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "- Dimension reduction\n",
    "    - use one-layer FC network w/o activation to replicate PCA\n",
    "    - can use *any* NN, single or multi-layer, with activations\n",
    "        - so more general\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gHxF58P28q4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoder (AE)\n",
    "\n",
    "An AE takes an input of volume $V_i$, passes it through a \"encoder\" NN $E$ whose final layer has volume $v_e$,\n",
    "and then passes the encoder's output into a \"decoder\" NN $D$ which produces a volume of size $V_d = V_i$.\n",
    "The goal is for the output of $D$ to be as close as possible to the input to $E$\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    " D(E(\\x))  & \\approx & \\x \\\\\n",
    " \\\\\n",
    "\\mathbf{z} & = & E(\\x) \\\\\n",
    "D(\\mathbf{z}) & = & \\x\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "If the volume of $z$ is strictly smaller than $D_i$, then the AE is *under complete* and at best\n",
    "$$ D(E(\\x)) \\approx \\x$$\n",
    "Essentially, $z$ is a reduced dimension representation of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "id": "biAjrkv4XJPi",
    "outputId": "89b91be6-062c-4145-de24-2cb79b81b94d",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_vanilla.jpg\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm35Tb5vkgI-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reconstruction Loss\n",
    "Minimize distance between $\\x$ and $D(E(\\x))$\n",
    "- RMS\n",
    "- cross entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl3yvTt749LB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## De-noising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "id": "C2Uwe6nAXnQI",
    "outputId": "7704afa2-df38-43b2-f189-29872ea2888d",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Denoising Autoencoder</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_denoising.jpg\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88IeMDsX3Y3-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Playing games with the Encoder representation\n",
    "\n",
    "What would happen if we fed the Decoder with some $z$ that did not correspond to any example in the training set ?\n",
    "\n",
    "- If we were lucky (and the Manifold Hypothesis were true) we would get something that looked similar to a training example\n",
    "  - that is, if the Encoder encoded syntactic \"concepts\"\n",
    "  - if it did encode \"concepts\", we can view the latent of each input as being a weighted combo of concept latents ?\n",
    "    - we could then manipulate any latent $z$ by some other latent that was a long/short portfolio of latents that were long the concept/short the concept\n",
    "      - \"top\"\n",
    "- There is no guarantee of being lucky !  It was not a training objective.  It is quite possible that we will output something that does not resemble a training example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variational Autoencoder (VAE): Generative ML\n",
    "\n",
    "Our objective in creating a VAE is to be able to generate outputs that could have come from the training distribution.\n",
    "\n",
    "Thus, our end goal is constructing a **decoder** that can generate (synthesize) outputs, not only that match the training data, but completely new outputs that are \"close\" to the training set.\n",
    "\n",
    "The encoder (which can be used for dimension reduction and transfer learning) is not the primary objective when building a VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a vanilla AE, the encoder produces a deterministic latent representation $\\z^\\ip$ given\n",
    "example $\\x^\\ip$.\n",
    "\n",
    "The decoder is only required to produce a valid output given a latent representation $\\z^\\ip$\n",
    "that corresponds to a concrete training input $\\x^\\ip$.\n",
    "\n",
    "Our goal is to be able to a produce \"realistic\" output given any latent $\\z$, even one that doesn't correspond\n",
    "to any training $\\x^\\ip$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The decoder will take a *latent vector* $\\z$ and produce $D(\\z)$, just as in a vanilla AE.\n",
    "\n",
    "\n",
    "The difference is that $\\z$ will be sampled from a *distribution* rather than being a concrete member of the training set.\n",
    "\n",
    "The encoder will take an input $\\x^\\ip$ and compute two\n",
    "values: $\\mu^\\ip$ and $\\sigma^\\ip$ which will serve as the mean and standard deviation of\n",
    "the distribution of $\\z^\\ip$ of the encoding of $\\x^\\ip$.\n",
    "\n",
    "As long as $\\z$ is sampled from this distribution, the decoder will produce a \"realistic\" output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note**\n",
    "\n",
    "$\\mu$ and $\\sigma$ are computed values (and hence, functions of $\\x$) and **not** parameters\n",
    "that are estimated (and become fixed after training).  So $\\mu$ and $\\sigma$ depend on the input --\n",
    "they are not constants.\n",
    "\n",
    "**CAN WE REFER to a cell in the Notebook ?  Chollet has $\\mu$ and $\\sigma$ as nodes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To train a VAE:\n",
    "- pass input $\\x^\\ip$ through the encoder, producing $\\mu^\\ip, \\sigma^\\ip$\n",
    "    - use $\\mu^\\ip, \\sigma^\\ip$ to sample a latent representation $\\z^\\ip$ from the distribution\n",
    "- pass the sampled $\\z^\\ip$ through the decoder, producing $D(\\z^\\ip)$\n",
    "- measure the reconstruction error $\\x^\\ip - D(\\z^\\ip)$, just as in a vanilla AE\n",
    "- backpropogate the error, updating all weights and $\\mu, \\sigma$\n",
    "\n",
    "Essentially, each input $\\x^\\ip$ has *many* latent representations (with different probabilities):\n",
    "any sample from the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe that, once trained, $D(\\z)$ should produce a realistic output, for any $\\z$ from the distribution.\n",
    "We can't control *which class* the output will come from though.\n",
    "\n",
    "A later innovation, called a  CVAE, will allow us to specify the output class too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Variational Autoencoder (VAE)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_VAE.jpg\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilistic formulation\n",
    "\n",
    "From the description of the VAE, observe that we are now dealing with distributions rather\n",
    "than deterministic values for\n",
    "- the encoding (latent representation) $\\z$\n",
    "- the output\n",
    "\n",
    "So we will need to describe these distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We begin with a distribution $p(\\z)$ of the latent variables, and a joint probabiity distribution $p(\\x, \\z)$ of examples and latents.\n",
    "\n",
    "We will approximate $p$, as usual, with a NN that we will parameterize with $\\theta$.\n",
    "So henceforth $p$ will be subscripted with $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From this joint distribution we can obtain\n",
    "- $p_\\theta(\\x|\\z) = \\frac{p_\\theta(\\x,\\z)}{p_\\theta(\\z)}$\n",
    "    - the conditional distribution of $\\x$ given $\\z$\n",
    "    - this represents the output distribution of the decoder\n",
    "\n",
    "- $p_\\theta(\\z|\\x) = \\frac{p_\\theta(\\x|\\z) p(\\z)}{p_\\theta(\\x)}$ (by Bayes rule)\n",
    "    - this represents the distribution for the encoder\n",
    "\n",
    "- $p_\\theta(\\x) = \\int_\\z p_\\theta(\\x|\\z) p(\\z)$\n",
    "    - the unconditional distribution of $\\x$, the input space, by marginalizing $\\z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We motivate these distributions as they relate to the VAE:\n",
    "- the encoder produces $p_\\theta(\\z|\\x)$\n",
    "- the decoder produces $p_\\theta(\\x|\\z)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The loss function: first attempt\n",
    "\n",
    "Let's try to create a loss function, given that we are dealing with probabilities.\n",
    "\n",
    "Our first attempt at reconstruction loss is $\\loss_R$:\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\loss_R(\\phi, \\theta, \\x ) & = & - \\E_{\\z \\sim p_\\phi(\\z|\\x)}\\left( \\log( p_\\theta(\\x | \\z) ) \\right) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is, we want to  maximize the probability of the decoder producing $\\x$ when the VAE inputs is $\\x$.\n",
    "$$\n",
    "\\E_{z \\sim p_\\phi(\\z|\\x)}\\left( \\log( p_\\theta(\\x | \\z) ) \\right)\n",
    "$$\n",
    "\n",
    "Note the sampling of encoder output $\\z \\sim p_\\phi(\\z|\\x)$ given input $\\x$\n",
    "and the probability of the decoder producing the same $\\x$: $p_\\theta(\\x | \\z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intractability\n",
    "\n",
    "It turns out that things are not so simple: Some of the distributions we need to deal with \n",
    "may not be *tractable*\n",
    "\n",
    "- they have no closed form, just empirical distributions\n",
    "- higher dimensional distributions may  pose computational issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can you spot the problem ?\n",
    "\n",
    "Recall that\n",
    "$$p_\\theta(\\x) = \\int_\\z p_\\theta(\\x|\\z) p(\\z)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But this integral is problematic.\n",
    "\n",
    "$\\z$ is multi-dimensional and to calculate the integral with respect to $\\z$ we have to\n",
    "integrate over the full range of each dimension.\n",
    "\n",
    "As the dimension of $\\z$ becomes large, it is no longer computationally tractable to numerically\n",
    "evaluate the integral.\n",
    "\n",
    "For the same reason $p_\\theta(\\z|\\x)$ is problematic since $p_\\theta(\\x)$ appears in the denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Avoiding intractability\n",
    "\n",
    "The solution is change the objective of the encoder\n",
    "from producing the intractable $p_\\theta(\\z|\\x)$ to producing an *approximation* $q_\\phi(\\z|\\x)$\n",
    "that is both tractable and \"close\" (in distribution) to the intractable $p_\\theta(\\z|\\x)$.\n",
    "\n",
    "As usual, we use the KL divergence as a measure of similarity of two distributions:\n",
    "\n",
    "$$\n",
    "\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x))\n",
    "$$\n",
    "\n",
    "$q_\\phi(\\z|\\x)$ will be implemented via a NN parameterized by $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It turns out that if we re-write the divergence between \n",
    "$q_\\phi(\\z|\\x)$ and $p_\\theta(\\z | \\x)$\n",
    "we obtain a term $\\loss$ that has a very intuitive interpretation and \n",
    "will serve as our modified Loss function.\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\loss & = & \\loss_R + \\loss_D \\\\\n",
    "\\loss_R(\\phi, \\theta, \\x ) & = & - \\E_{\\z \\sim q_\\phi(\\z|\\x)}\\left( \\log( p_\\theta(\\x | \\z) ) \\right) \\\\\n",
    "\\loss_D(\\phi, \\x) & = & \\KL \\left(  q_\\phi(\\z|\\x) \\; || \\; p_\\theta(\\z) \\right) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $\\KL(f,g)$ denotes the KL divergence between distributions $f$ and $g$.\n",
    "\n",
    "That is, our  new loss $\\loss$ function has two components\n",
    "- $\\loss_R$\n",
    "    - the reconstruction loss, as before, but using the encoder $q_\\phi(\\z|\\x)$ instead of $p_\\theta(\\z|\\x)$\n",
    "\n",
    "- $\\loss_D$\n",
    "    - the \"KL divergence\" loss which constrains the approximate $q_\\phi(\\z|\\x)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Advanced: Obtain $\\loss$ by rewriting $\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x)$\n",
    "\n",
    "Kumar lecture 22, @9:00 - @11:00\n",
    "\n",
    "You might be puzzled that \n",
    "$$\n",
    "\\loss_D = \\KL \\left(  q_\\phi(\\z|\\x) \\; || \\; p_\\theta(\\z) \\right)\n",
    "$$\n",
    "rather than\n",
    "$$\n",
    "\\loss_D = \\KL \\left(  q_\\phi(\\z|\\x) \\; || \\; p_\\theta(\\z | \\x) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's examine the discrepancy between the approximation $q_\\phi(\\z|\\x)$ and $p_\\theta(\\z | \\x)$\n",
    "\n",
    "$\n",
    "\\begin{array}[llll]\\\\\n",
    "\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x)) &  = & \\sum_z{ q_\\phi(\\z|\\x )(\\log(q_\\phi(\\z|\\x) - \\log(p_\\theta(\\z | \\x)) } & \\text{def. of KL} \\\\\n",
    "&  = & \\E_z \\left( \\log(q_\\phi(\\z|\\x) - \\log(p_\\theta(\\z | \\x)) \\right) & \\text{def. of }\\E \\\\\n",
    "&  = & \\E_z ( \\; \\log(q_\\phi(\\z|\\x)) \\\\ & & -\\left( \\; \\log( p_\\theta(\\x | \\z)) + \\log(p_\\theta(\\z)) - \\log(p_\\theta(\\x) \\right)    \\,   )  \\;\\;)&  \\text{Bayes theorem on } \\\\\n",
    " & & & \\log(p_\\theta(\\z | \\x)) \\\\\n",
    "\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x)) \\\\ - \\log(p_\\theta(\\x)) & = & \\E_z \\left( \\; \\log(q_\\phi(\\z|\\x))  - \\left( \\log( p_\\theta(\\x | \\z) ) + \\log( p_\\theta(\\z) ) \\right) \\;\\right) & \\text{ move } \\log(p_\\theta(\\x)) \\text{ to LHS} \\\\\n",
    " & = & \\E_z \\left( \\; (\\log(q_\\phi(\\z|\\x))  - \\log( p_\\theta(\\z) ) )  - \\log( p_\\theta(\\x | \\z) )   \\; \\right) & \\\\\n",
    " & = & - \\E_z \\left( \\log( p_\\theta(\\x | \\z) ) \\right) + \\KL(q_\\phi(\\z|\\x) \\; ||\\;  p_\\theta(\\z) ) & \\text{def. of KL} \\\\\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe that the LHS would seem to be a reasonable loss function\n",
    "- maximizing the log likelihood of the training set $p_\\theta(\\x)$\n",
    "- keeping the approximation $q_\\phi(\\z|\\x)$ close to $p_\\theta(\\z | \\x)$\n",
    "\n",
    "So we maximize the \"fit\" to the training set $\\X$ (maximizing likelihood) while keeping\n",
    "the approximation error small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The LHS cannot be optimized via SGD (recall the tractability issue with $p_\\theta(\\x)$ and  $p_\\theta(\\z|\\x)$).\n",
    "\n",
    "**But the RHS can be made tractable** giving a proper choice of $p_\\theta(\\z)$.\n",
    "\n",
    "So the RHS is a tractable form that is equivalent to the LHS and will serve as the loss function\n",
    "for the VAE.\n",
    "\n",
    "[VAE tutorial](https://arxiv.org/pdf/1606.05908.pdf) page 8 observes that the RHS has\n",
    "the form of an autoencoder ($q_\\phi(\\z|\\x)$ looks like an encoder; $p_\\theta(\\x|\\z)$ looks like a decoder).\n",
    "\n",
    "So it may be fair to say that the idea for the VAE is obtained from the Loss function,\n",
    "rather than vice-versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing $p_\\theta(\\z)$\n",
    "\n",
    "So what distribution should we use for the prior $p_\\theta(\\z)$ ?\n",
    "\n",
    "One important consideration is that, since we learn by SGD, we need to be able to differentiate.\n",
    "\n",
    "Another consideration is that the functional form of the distribution (i.e., an empirical distribution doesn't have a closed functional form) may simplify the math (e.g. normal).\n",
    "\n",
    "To force the tractability of $q_\\phi(\\z|\\x)$ we\n",
    "will define *prior distribution* $p_\\theta(\\z)$ to have a tractable, closed form (often a normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVIedxZelBZN",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loss function: discussion\n",
    "\n",
    "**Expand, as per Kumar**\n",
    "\n",
    "The reconstruction loss should be familiar: it tries to force the decoded output to be \"close\" to\n",
    "the input.\n",
    "\n",
    "What would happen if we omitted the KL divergence constraint $\\loss_D$ from $\\loss$ ?\n",
    "\n",
    "Without it, the model could theoretically learn encodings $q_\\phi(\\z|\\x)$ whose\n",
    "distribution had near zero variance.\n",
    "This would collapse the VAE into the vanilla AE.\n",
    "So by choosing $p_\\theta(\\z)$ with a non-zero variance, we force the encoder to be probabilistic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variational inference\n",
    "\n",
    "**NEEDS WORk, or omit.  Really only need to discuss ELBO, if anything**\n",
    "\n",
    "The cost/loss needs to be simplified quite a bit.\n",
    "This is beyond the scope of this talk but we refer the reader to\n",
    "[VAE tutorial](https://arxiv.org/pdf/1606.05908.pdf) (Also recommended by Geron in footnote 7, Chapt 15).\n",
    "\n",
    "To summarize\n",
    "- we still have an intractable term (appears as another $\\KL$ divergence after re-writing cost/loss\n",
    "    - this term appears as an additive term\n",
    "    - by definition of $\\KL$, it is positive\n",
    "- so we can't evaluate the full cost/loss function\n",
    "    - but, ignoring the intractable positive part, the remainder is a *lower bound* on the cost/loss\n",
    "        - so we optimize the lower bound\n",
    "        - called the *ELBO* term (LB is lower bound)\n",
    "        \n",
    " See page 6 in particular. The probablility $Prob(x)$ is the same as the x as from $Prob(z|x)$ via Bayes.\n",
    " **But** isssue for us is $q(z|x)$ ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnFvZdJ1sV_e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Re-parameterization trick\n",
    "\n",
    "Re-parameterization trick moves the sampling to the side. Figure 4 from https://arxiv.org/pdf/1606.05908.pdf\n",
    "\n",
    "There is still one more problem for training:\n",
    "- sampling $\\hat{\\z}  \\sim  q_\\phi(\\z|\\x)$\n",
    "\n",
    "This is not a problem in the forward pass.\n",
    "Optimization via back propogation requires the ability to take derivatives of the loss wrt the trainable parameters.\n",
    "\n",
    "How do we take the derivative of a node involving a random choice ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnFvZdJ1sV_e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The trick is to re-express $z$:\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\mathbf{z}  & = & \\mathbf{\\mu} + \\mathbf{\\sigma} \\mathbf{\\epsilon} \\\\\n",
    "\\mathbf{\\epsilon} & \\sim & \\hat{p}(\\mathbf{z}) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is, we obtain $z$ by sampling an $\\epsilon$ from the constraining distribution $\\hat{p}(z)$, scaling the random $\\epsilon$ by some learnable paramter $\\sigma$ and adding learnable paramater $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnFvZdJ1sV_e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We still can't take derivatives of $L_R$ with respect to $\\epsilon$, but we don't need to !\n",
    "\n",
    "We only need to take derivates of $L_R$ with respect to $\\phi, \\theta, \\mu, \\sigma$, which we can do.\n",
    "\n",
    "In evaluating derivatives, the $\\epsilon$ that appears in the result (e.g., derivative wrt $\\sigma$) can be treated as a constant.\n",
    "\n",
    "- For a particular example, we can remember the  drawn $\\epsilon$ in the forward pass and use it in the backward pass ?\n",
    "  - but over a batch, the expected value over the drawn $\\epsilon$ should be $E( \\hat{p}(z) )$ (which is $0$ is we constrain $\\hat{p}$ to be $0$ centered)\n",
    "  \n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "L_D(\\phi, \\mathbf{\\mu}, \\mathbf{\\sigma}, \\mathbf{x}) & = & D_{\\text{KL}} \\left(  q_\\phi(\\z|\\x), \\hat{p}_{\\mathbf{\\mu}, \\mathbf{\\sigma}}(\\z) \\right) \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Reparameterization trick</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Reparameterization_trick.jpg\" width=800></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbWCKt7Or89C",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "**Training**\n",
    "\n",
    "Encoder produces\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "E(\\x) & = &  q_\\phi(\\z|\\x) & \\approx & p_\\theta(\\z|\\x) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We sample from\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\hat{\\z} & \\sim & q_\\phi(\\z|\\x) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Decoder produces\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "D(\\hat{\\z})  & = & p_\\theta (\\x|\\z)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Each time (epoch) that we encounter the same training example, we select another random element from the distribution.\n",
    "\n",
    "So the VAE learns to represent the same example from multiple latents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbWCKt7Or89C",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Generative**\n",
    "- sample $\\hat{\\z} \\sim \\hat{p}(\\z)$\n",
    "- use decoder to produce output $p_\\theta (\\x|\\z)$\n",
    " \n",
    "This means we can feed in a $\\z$ that doesn't correspond to any training example and perhaps get an output that *resembles* something from the training set, rather than noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kaLKMwF5bOR",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditional Variational Autoencoder (CVAE)\n",
    "\n",
    "\n",
    "\n",
    "So far, a VAE will allow us to input an aribtrary $z$ and get a \"reasonable\" output, that is, something that resembles a training example.\n",
    "\n",
    "However, we don't have any control as to *which* class the output will come from.\n",
    "\n",
    "But the training examples sometimes come with labels, that partitions the training set into classes (each: particular digit in MNIST).\n",
    "\n",
    "How about controlling *which* digit is generated by passing in the desired label as an input ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kaLKMwF5bOR",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is remedied in CVAE by\n",
    "- modifying the input of the Encoder to also take a label (e.g., class id)\n",
    " - modifiying the input of the Decoder to also take a label\n",
    " \n",
    "So the Encoder output is a distribution that is conditional both on the input image **and** the class label.\n",
    "\n",
    "Similarly the Decoder output is conditional on the latent **and** the class label.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kaLKMwF5bOR",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So now we can create a latent, append a class label, and presumably have the decoder produce an output from the desired class.\n",
    "\n",
    "Thus, the encoding distribution is now conditional on class label $c$: $q_\\phi(z|x,c)$ \n",
    "and so is the encoding distribution $p_\\theta(x|z,c)$ \n",
    "\n",
    "Again, by restricting the functional form of the prior distribution $\\hat{p}$ we can simplify the math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Conditional VAE (CVAE)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_CVAE.jpg\"\" width=800></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Layer-wise pre-training with Autoencoders\n",
    "\n",
    "Autoencoders these days can be used for dimension reduction.\n",
    "\n",
    "Moreover, they were an important transitional step (albeit no longer relevant)\n",
    "in the history of DL. \n",
    "\n",
    "Before we learned all the tricks (better initialization, better activation functions, normalization)\n",
    "that enable us to train deep networks today, autoencoders played a vital role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For each layer $\\ll$ in sequence, starting from the input layer: train layer $l$'s weights using an\n",
    "autoencoding objective (to have the output of the layer replicate it's input).\n",
    "\n",
    "This is, in effect, an initilization of the layer's weights that is better than random.\n",
    "\n",
    "(Presumably, by being able to encode the syntactic structure of the training set, the weights have\n",
    "learned something useful.)\n",
    "\n",
    "For a brief time in history, this was the solution to the difficulty of not learning because of poor initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autoencoders and Transfer Learning\n",
    "Today, autoencoders are useful for another purpose: Transfer Learning.\n",
    "\n",
    "If we can train an AE network to create features that are useful for reconstruction, it is possible\n",
    "that these features are useful for solving more complicated tasks.\n",
    "\n",
    "So it is not uncommon to approach a complicated problem by first constructing an autoencoder to\n",
    "come up with an alternate (and smaller) representation of the input space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that Autoencoders are *unsupervised*: they don't take labels.  \n",
    "\n",
    "So the encodings they produce\n",
    "stress syntactic similarity, rather than semantic similarity.\n",
    "\n",
    "Their use in Transfer Learning depends on the hope that inputs that are syntactically similar also\n",
    "have the same labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Autoencoders_and_Generative_Models.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
