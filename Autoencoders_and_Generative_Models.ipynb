{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{\\tp}{\\mathbf{{(t)}}}\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro `_latex_std_` created. To execute, type its name (without quotes).\n",
      "=== Macro contents: ===\n",
      "get_ipython().run_line_magic('run', 'Latex_macros.ipynb')\n",
      " "
     ]
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYek5uDM0gmo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AutoEncoder (AE): High Level\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>TL;DR</b> \n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>The Deep Learning analog of Principal Components (PCA)</li>\n",
    "        <ul>\n",
    "            <li>Most of the lessons of AE apply equally to PCA</li>\n",
    "        </ul>\n",
    "        <li>Unsupervised: no labels (really semi-supervised)</li>\n",
    "        <li>Create \"synthetic features\" from the original set of features</li>\n",
    "        <li>May be able to use reduced set of synthetic features (dimensionality reduction)</li>\n",
    "        <li><b>Generative (vs Discriminative)</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "id": "biAjrkv4XJPi",
    "outputId": "89b91be6-062c-4145-de24-2cb79b81b94d",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_vanilla.jpg\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An Autoencoder is\n",
    "- A NN consisting of two halves\n",
    "- An *Encoder* sequence of layers\n",
    "    - transforms inputs $\\x^\\ip$ to synthetic features $\\z^\\ip$\n",
    "    - *latent representation*\n",
    "- A *Decoder* sequence of layers\n",
    "    - \"inverts\" latent representation $\\z^\\ip$ to recover $\\x^\\ip$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYek5uDM0gmo",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Encoder and Decoder are *jointly trained*, not trained separately !\n",
    "- No obvious target for training the Encoder\n",
    "- Semi-supervised\n",
    "    - No labels\n",
    "    - But we use $\\x^\\ip$ as the \"label\" associated with example $\\x^\\ip$ in training\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gHxF58P28q4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This should all be reminiscent of the definition of Principal Components.\n",
    "\n",
    "Just as for PCA, we can perform dimension-reduction\n",
    "- size of latent representation $| \\z | \\le n$\n",
    "\n",
    "When $| \\z | \\lt n$ we say \n",
    "- that the input has been passed through a *bottleneck*\n",
    "- that the AE is *under complete*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The *main difference* from PCA\n",
    "- PCA uses a *linear* transformation\n",
    "- NN can use *non-linear* transformations too\n",
    "    - PCA as a special case of AE\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYek5uDM0gmo",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Autoencoders: Uses\n",
    "\n",
    "## Dimension reduction\n",
    "\n",
    "After training\n",
    "- we can discard the Decoder\n",
    "- use the Encoder output (synthetic features) as reduced dimension inputs to a *new* task\n",
    "    - Encoder weights are **frozen**: non-learnable when training new task\n",
    "   - It may be easier to solve the new task given $\\z$ rather than $\\x$\n",
    "       - have already discovered \"structure\" of $\\x$\n",
    "   - *Transfer Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder: Encoder + New head</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_encoder_new_head.jpg\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In PCA, we eliminated original features that were \"less important\"\n",
    "- i.e., explained variation among only a small fraction of the training set\n",
    "    - recall how we redominated explained variance in terms of \"number of features\"\n",
    "    \n",
    "There is no direct similar concept of feature importance in AE\n",
    "- other than minimizing a Cost function, which *may* wind up focussing on \"important\" features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Layer-wise pre-training with Autoencoders\n",
    "\n",
    "Autoencoders played a vital role in the development of Deep Learning:\n",
    "- They made it possible to train otherwise untrainable NN's.\n",
    "- Other innovations supplanted the need for AE's to assist training\n",
    "    - better initialization\n",
    "    - better activations functions\n",
    "    - normalization\n",
    " \n",
    "Although they are no longer needed for that purpose, it is interesting to see how (and why) they were used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a NN with $L$ layers that solves a Supervised Learning Problem\n",
    "- Training attempts to learn the weights of all layers simultaneously\n",
    "- *Layer wise pre-training* was an attempt\n",
    "    - to *initialize* the weights of each layer\n",
    "    - in succession\n",
    "    - so that the task of simultaneously solving for optimal weights had a better chance of succeeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The idea was to learn an initialization of $\\W_\\llp$, the weights of layer $l$.\n",
    "- After having learned the weights $\\W_{(l')}$ for all layers $l' \\lt l$.\n",
    "\n",
    "\n",
    "To initialize $\\W_\\llp$:\n",
    "- Train an AE that takes $\\x^\\ip$ as input\n",
    "- Using initialized weights $\\W_{(l')}$ for all layers $l' \\lt l$\n",
    "- Produces $\\tx^\\ip$ at layer $l$'s output $\\y_\\llp$\n",
    "\n",
    "So weight initializations were learned layer by layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that the labels $\\y^\\ip$ *were not used* !\n",
    "- wouldn't be useful for the shallow NN\n",
    "\n",
    "It was thought\n",
    "- to be easier to learn the structure of the input $\\x$ independent of the labels\n",
    "- to be easier to learn $\\W_\\llp$ incrementally\n",
    "\n",
    "One the weights $\\W_\\llp$ were initialized via AE's\n",
    "- training of the Supervised Learning task had a better chance of succeeding\n",
    "- compared to any other initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autoencoders and Transfer Learning\n",
    "Today, autoencoders are useful for another purpose: Transfer Learning.\n",
    "\n",
    "If we can train an AE network to create features that are useful for reconstruction\n",
    "- it is possible\n",
    "that these features are useful for solving more complicated tasks.\n",
    "\n",
    "This was in essence what\n",
    "- Our dimension reduction example (replace the head) was doing\n",
    "- Layerwise Pre-training was attempting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So it is not uncommon to approach a complicated problem\n",
    "- by first constructing an autoencoder to\n",
    "come up with an alternate (and smaller) representation of the input space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that Autoencoders are *unsupervised*: they don't take labels.  \n",
    "\n",
    "So the encodings they produce\n",
    "stress syntactic similarity, rather than semantic similarity.\n",
    "\n",
    "Their use in Transfer Learning depends on the hope that inputs that are syntactically similar also\n",
    "have the same labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Denoising\n",
    "\n",
    "Very much like dimension reduction but with the assumption that\n",
    "- \"less important\" features are just random noise that is added to the true example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Artificial Intelligence\n",
    "\n",
    "A less obvious use of AE (using the Decoder rather than the Encoder) is to *generate* examples.\n",
    "\n",
    "Most of the Machine Learning we have studied thus far is *discriminative*\n",
    "- $\\pr{\\hat{\\y}^\\ip | \\x^\\ip )}$\n",
    "    - e.g., classifier: discriminate among the possible classes $\\y^\\ip$, given example $\\x^\\ip$\n",
    "\n",
    "We can use the Decoder on *arbitrary* $\\z$ to *generate* a completely  new $\\x$:\n",
    "- $\\pr{ \\x^{(i')} | \\z^{(i')} }$ for some $i'$ not in training\n",
    "- *generate* a new example $i'$, in the domain of $\\x$, that was not encountered during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Generator</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_decoder.jpg\" width=800</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gHxF58P28q4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoder (AE): Details\n",
    "\n",
    "The *task* that trains an Autoencoder\n",
    "- Given input $\\x^\\ip$\n",
    "- Output of Encoder: $\\z^\\ip = E(\\x^\\ip)$\n",
    "- Output of Decoder: $\\tx^\\ip = D(\\z^\\ip)$\n",
    "- \"Target\": $\\x^\\ip$\n",
    "\n",
    "Both the Encoder and Decoder are parameterized (learnable parameters)\n",
    "- Goal: find the parameters such that \n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    " \\tx^\\ip = D(E(\\x))  & \\approx & \\x \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$\\z^\\ip = E(\\x^\\ip)$ is the latent representation of $\\x^\\ip$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm35Tb5vkgI-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cost/Loss function\n",
    "\n",
    "There are two obvious candidates for per-example loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm35Tb5vkgI-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mean Squared Error (MSE)\n",
    "$$\n",
    "\\loss^\\ip = \\sum_{j=1}^{|\\z|} { (\\x^\\ip_j - \\tx^\\ip_j)^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm35Tb5vkgI-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary Cross Entropy\n",
    "\n",
    "For the special case where *each* original feature is in the range $[0,1]$\n",
    "- e.g., pixel is on/off\n",
    "- we can treat each original feature as a probability and use Binary Cross Entropy\n",
    "\n",
    "$$\n",
    "\\loss^\\ip = \\sum_{j=1}^{|\\z|} {  \\left( \\x^\\ip_j    \\log(\\tx^\\ip_j) + ( 1 - \\x^\\ip_j ) \\log(1 - \\tx^\\ip_j) \\right) }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl3yvTt749LB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Autoencoder: extensions\n",
    "\n",
    "There are some extensions of the \"vanilla\" Autoencoder we have described thus far.\n",
    "\n",
    "## De-noising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "colab_type": "code",
    "id": "C2Uwe6nAXnQI",
    "outputId": "7704afa2-df38-43b2-f189-29872ea2888d",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Denoising Autoencoder</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_denoising.jpg\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variational Autoencoder (VAE): Generative ML\n",
    "\n",
    "Observe that the Decoder part of the \"vanilla\" AE $D( \\z^\\ip )$\n",
    "- has been trained to produce \"realistic\" $\\tx^\\ip$ *only* for a $\\z^\\ip = E(\\x^\\ip)$\n",
    "    - i.e., \"realistic\": appears to come from the distribution of training $\\X$\n",
    "- there is no guarantee that $D( \\z^{(i')} )$ for some $i'$ not in training is realistic\n",
    "\n",
    "That is: the AE has not been trained to *extrapolate* beyond the training inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A VAE is able generate outputs \n",
    "- that *could have* come from the training distribution from a latent representation $\\z^{(i')}$ \n",
    "- but that *did not* come from $\\X$.\n",
    "\n",
    "Our goal is constructing a **Decoder** that can extrapolate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Variational Autoencoder (VAE)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_VAE.jpg\" width=1200></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Decoder will take a *latent vector* $\\z$ and produce $D(\\z)$, just as in a vanilla AE.\n",
    "\n",
    "\n",
    "The difference is that $\\z$ will be sampled from a *distribution* rather than being a \n",
    "unique mapping of a training example.\n",
    "\n",
    "This will be done by modifying the Encoder\n",
    "- It will *indirectly* create $\\z^\\ip$\n",
    "- It will compute *variables* $\\mu^\\ip$ and $\\sigma^\\ip$\n",
    "    - $\\z^\\ip$ will be *sampled* from a distribution with mean $\\mu^\\ip$ and standard deviations $\\sigma^\\ip$\n",
    "    \n",
    "As long as $\\z$ is sampled from this distribution, the decoder will produce a \"realistic\" output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note**\n",
    "\n",
    "$\\mu$ and $\\sigma$ are computed values (and hence, functions of $\\x$) and **not** parameters\n",
    "- so training learns a *function* from $\\x^\\ip$ to $\\mu^\\ip$ and $\\sigma^\\ip$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To train a VAE:\n",
    "- pass input $\\x^\\ip$ through the encoder, producing $\\mu^\\ip, \\sigma^\\ip$\n",
    "    - use $\\mu^\\ip, \\sigma^\\ip$ to sample a latent representation $\\z^\\ip$ from the distribution\n",
    "- pass the sampled $\\z^\\ip$ through the decoder, producing $D(\\z^\\ip)$\n",
    "- measure the reconstruction error $\\x^\\ip - D(\\z^\\ip)$, just as in a vanilla AE\n",
    "- backpropogate the error, updating all weights and $\\mu, \\sigma$\n",
    "\n",
    "Essentially, each input $\\x^\\ip$ has *many* latent representations (with different probabilities):\n",
    "any sample from the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbWCKt7Or89C",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Training**\n",
    "\n",
    "Encoder produces\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "E(\\x) & = &  q_\\phi(\\z|\\x) & \\approx & p_\\theta(\\z|\\x) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We sample from\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\hat{\\z} & \\sim & q_\\phi(\\z|\\x) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Decoder produces\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "D(\\hat{\\z})  & = & p_\\theta (\\x|\\z)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Each time (epoch) that we encounter the same training example, we select another random element from the distribution.\n",
    "\n",
    "So the VAE learns to represent the same example from multiple latents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbWCKt7Or89C",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Generative**\n",
    "- sample $\\hat{\\z} \\sim \\hat{p}(\\z)$\n",
    "- use decoder to produce output $p_\\theta (\\x|\\z)$\n",
    " \n",
    "This means we can feed in a $\\z$ \n",
    "- that doesn't correspond to any training example\n",
    "- and perhaps get an output that *resembles* something from the training set, rather than noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFfhVRnM3C7q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditional VAE\n",
    "\n",
    "Once a VAE is trained, $D(\\z)$ should produce a realistic output, for any $\\z$ from the distribution.\n",
    "\n",
    "However, if the distribution of $\\X$ includes examples from many classes \n",
    "- Assuming we have labels as auxilliary information (not used in training)\n",
    "    - e.g., the 10 digits\n",
    "- The VAE can't control *which class* the output will come from\n",
    "\n",
    "A *Conditional VAE* allow our generator (Decoder) to control the class $c$ of the output $\\tx$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Conditional VAE (CVAE)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_CVAE.jpg\"\" width=800></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kaLKMwF5bOR",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The class label $c$\n",
    "- is given as part of *training*\n",
    "    - So the Encoder produces a distribution that is conditioned on *both* $\\x$ and $c$.\n",
    "- is an *additional parameter* of the Decoder\n",
    "    - So the output class can be controlled\n",
    "$$\n",
    "\\tx^\\ip = D(\\z^\\ip, c)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kaLKMwF5bOR",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So now we \n",
    "- create a latent $\\z$\n",
    "- append a class label $c$\n",
    "- and presumably have the decoder produce an output from the desired class.\n",
    "\n",
    "- The encoding distribution is now conditional on class label $c$: $q_\\phi(z|x,c)$ \n",
    "- So is the decoding distribution $p_\\theta(x|z,c)$ \n",
    "\n",
    "Again, by restricting the functional form of the prior distribution $\\hat{p}$ we can simplify the math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Detour: Autoencoder notebook on Colab\n",
    "\n",
    "Let's examine some Keras code that implements several types of Autoencoders\n",
    "- Vanilla\n",
    "- Denoising\n",
    "- VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will write our AE's using the Keras *Functional* API rather than the *Sequential* model\n",
    "- We *could* write the complete AE using the Sequential API\n",
    "- **But**\n",
    "    - we want to extract the Encoder and Decoder parts as *separate models*\n",
    "    - we can do this with the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will now switch to a notebook running on Google Colab\n",
    " [Autoencoder example from github](https://colab.research.google.com/github/kenperry-public/ML_Fall_2019/blob/master/Autoencoder_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VAE: Probabilistic formulation\n",
    "\n",
    "**Note**: Advanced material\n",
    "\n",
    "The mathematical derivation of a VAE is quite detailed\n",
    "- it is interesting but not absolutely necessary to understand\n",
    "\n",
    "The interested reader is refered to a highly recommended [VAE tutorial](https://arxiv.org/pdf/1606.05908.pdf).\n",
    "\n",
    "We will try to give the essence in the following slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>TL;DR</b> \n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>The VAE has a very interesting <b>two part</b> Loss Function</li>\n",
    "        <ul>\n",
    "            <li>Reconstruction Loss, as in the Vanilla AE</li>\n",
    "            <li>Divergence Loss\n",
    "        </ul>\n",
    "        <li>The Reconstruction Loss is not sufficient</li>\n",
    "        <ul>\n",
    "            <li>Issues of intractability arise</li>\n",
    "            <li>The Divergence Loss skirts intractability</li>\n",
    "            <ul>\n",
    "                <li>By constraining the Encoder to produce a tractable distribution</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the description of the VAE, observe that we are now dealing with distributions rather\n",
    "than deterministic values for\n",
    "- the encoding (latent representation) $\\z$\n",
    "- the output\n",
    "\n",
    "So we will need to describe these distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We begin with a distribution $p(\\z)$ of the latent variables, and a joint probabiity distribution $p(\\x, \\z)$ of examples and latents.\n",
    "\n",
    "We will approximate $p$, as usual, with a NN that we will parameterize with $\\theta$.\n",
    "So henceforth $p$ will be subscripted with $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From this joint distribution we can obtain\n",
    "- $p_\\theta(\\x|\\z) = \\frac{p_\\theta(\\x,\\z)}{p_\\theta(\\z)}$\n",
    "    - the conditional distribution of $\\x$ given $\\z$\n",
    "    - this represents the output distribution of the decoder\n",
    "\n",
    "- $p_\\theta(\\z|\\x) = \\frac{p_\\theta(\\x|\\z) p(\\z)}{p_\\theta(\\x)}$ (by Bayes rule)\n",
    "    - this represents the distribution for the encoder\n",
    "\n",
    "- $p_\\theta(\\x) = \\int_\\z p_\\theta(\\x|\\z) p(\\z)$\n",
    "    - the unconditional distribution of $\\x$, the input space, by marginalizing $\\z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We motivate these distributions as they relate to the VAE:\n",
    "- the encoder produces $p_\\theta(\\z|\\x)$\n",
    "- the decoder produces $p_\\theta(\\x|\\z)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The loss function: first attempt\n",
    "\n",
    "Let's try to create a loss function, given that we are dealing with probabilities.\n",
    "\n",
    "Our first attempt at reconstruction loss is $\\loss_R$:\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\loss_R(\\phi, \\theta, \\x ) & = & - \\E_{\\z \\sim p_\\phi(\\z|\\x)}\\left( \\log( p_\\theta(\\x | \\z) ) \\right) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is, we want to  maximize the probability of the decoder producing $\\x$ when the VAE inputs is $\\x$.\n",
    "$$\n",
    "\\E_{z \\sim p_\\phi(\\z|\\x)}\\left( \\log( p_\\theta(\\x | \\z) ) \\right)\n",
    "$$\n",
    "\n",
    "Note the sampling of encoder output $\\z \\sim p_\\phi(\\z|\\x)$ given input $\\x$\n",
    "and the probability of the decoder producing the same $\\x$: $p_\\theta(\\x | \\z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intractability\n",
    "\n",
    "It turns out that things are not so simple: \n",
    "- Some of the distributions we need to deal with \n",
    "may not be *tractable*\n",
    "\n",
    "- They have no closed form, just empirical distributions\n",
    "- Higher dimensional distributions may  pose computational issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can you spot the problem ?\n",
    "\n",
    "Recall that\n",
    "$$p_\\theta(\\x) = \\int_\\z p_\\theta(\\x|\\z) p(\\z)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But this integral is problematic.\n",
    "\n",
    "$\\z$ is multi-dimensional and to calculate the integral with respect to $\\z$ we have to\n",
    "integrate over the full range of each dimension.\n",
    "\n",
    "As the dimension of $\\z$ becomes large, it is no longer computationally tractable to numerically\n",
    "evaluate the integral.\n",
    "\n",
    "For the same reason $p_\\theta(\\z|\\x)$ is problematic since $p_\\theta(\\x)$ appears in the denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Avoiding intractability\n",
    "\n",
    "The solution is change the objective of the encoder\n",
    "- from producing the intractable $p_\\theta(\\z|\\x)$ \n",
    "- to producing an *approximation* $q_\\phi(\\z|\\x)$\n",
    "- that is both tractable and \"close\" (in distribution) to the intractable $p_\\theta(\\z|\\x)$.\n",
    "\n",
    "As usual, we use the KL divergence as a measure of similarity of two distributions:\n",
    "\n",
    "$$\n",
    "\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x))\n",
    "$$\n",
    "\n",
    "$q_\\phi(\\z|\\x)$ will be implemented via a NN parameterized by $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It turns out that if we re-write the divergence between \n",
    "$q_\\phi(\\z|\\x)$ and $p_\\theta(\\z | \\x)$\n",
    "- We obtain a term $\\loss$ that has a very intuitive interpretation\n",
    "- Will serve as our modified Loss function.\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\loss & = & \\loss_R + \\loss_D \\\\\n",
    "\\loss_R(\\phi, \\theta, \\x ) & = & - \\E_{\\z \\sim q_\\phi(\\z|\\x)}\\left( \\log( p_\\theta(\\x | \\z) ) \\right) \\\\\n",
    "\\loss_D(\\phi, \\x) & = & \\KL \\left(  q_\\phi(\\z|\\x) \\; || \\; p_\\theta(\\z) \\right) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $\\KL(f,g)$ denotes the KL divergence between distributions $f$ and $g$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is, our  new loss $\\loss$ function has two components\n",
    "- $\\loss_R$\n",
    "    - the reconstruction loss, as before, but using the encoder $q_\\phi(\\z|\\x)$ instead of $p_\\theta(\\z|\\x)$\n",
    "\n",
    "- $\\loss_D$\n",
    "    - the \"KL divergence\" loss which constrains the approximate $q_\\phi(\\z|\\x)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Advanced: Obtain $\\loss$ by rewriting $\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x)$\n",
    "\n",
    "You might be puzzled that \n",
    "$$\n",
    "\\loss_D = \\KL \\left(  q_\\phi(\\z|\\x) \\; || \\; p_\\theta(\\z) \\right)\n",
    "$$\n",
    "rather than\n",
    "$$\n",
    "\\loss_D = \\KL \\left(  q_\\phi(\\z|\\x) \\; || \\; p_\\theta(\\z | \\x) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's examine the discrepancy between the approximation $q_\\phi(\\z|\\x)$ and $p_\\theta(\\z | \\x)$\n",
    "\n",
    "$\n",
    "\\begin{array}[llll]\\\\\n",
    "\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x)) &  = & \\sum_z{ q_\\phi(\\z|\\x )(\\log(q_\\phi(\\z|\\x) - \\log(p_\\theta(\\z | \\x)) } & \\text{def. of KL} \\\\\n",
    "&  = & \\E_z \\left( \\log(q_\\phi(\\z|\\x) - \\log(p_\\theta(\\z | \\x)) \\right) & \\text{def. of }\\E \\\\\n",
    "&  = & \\E_z ( \\; \\log(q_\\phi(\\z|\\x)) \\\\ & & -\\left( \\; \\log( p_\\theta(\\x | \\z)) + \\log(p_\\theta(\\z)) - \\log(p_\\theta(\\x) \\right)    \\,   )  \\;\\;)&  \\text{Bayes theorem on } \\\\\n",
    " & & & \\log(p_\\theta(\\z | \\x)) \\\\\n",
    "\\KL( q_\\phi(\\z|\\x) \\; ||\\; p_\\theta(\\z | \\x)) \\\\ - \\log(p_\\theta(\\x)) & = & \\E_z \\left( \\; \\log(q_\\phi(\\z|\\x))  - \\left( \\log( p_\\theta(\\x | \\z) ) + \\log( p_\\theta(\\z) ) \\right) \\;\\right) & \\text{ move } \\log(p_\\theta(\\x)) \\text{ to LHS} \\\\\n",
    " & = & \\E_z \\left( \\; (\\log(q_\\phi(\\z|\\x))  - \\log( p_\\theta(\\z) ) )  - \\log( p_\\theta(\\x | \\z) )   \\; \\right) & \\\\\n",
    " & = & - \\E_z \\left( \\log( p_\\theta(\\x | \\z) ) \\right) + \\KL(q_\\phi(\\z|\\x) \\; ||\\;  p_\\theta(\\z) ) & \\text{def. of KL} \\\\\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe that the LHS would seem to be a reasonable loss function\n",
    "- maximizing the log likelihood of the training set $p_\\theta(\\x)$\n",
    "- keeping the approximation $q_\\phi(\\z|\\x)$ close to $p_\\theta(\\z | \\x)$\n",
    "\n",
    "So we maximize the \"fit\" to the training set $\\X$ (maximizing likelihood) while keeping\n",
    "the approximation error small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The LHS cannot be optimized via SGD (recall the tractability issue with $p_\\theta(\\x)$ and  $p_\\theta(\\z|\\x)$).\n",
    "\n",
    "**But the RHS can be made tractable** giving a proper choice of $p_\\theta(\\z)$.\n",
    "\n",
    "So the RHS is a tractable form that is equivalent to the LHS and will serve as the loss function\n",
    "for the VAE.\n",
    "\n",
    "So it may be fair to say that the idea for the VAE is obtained from the Loss function,\n",
    "rather than vice-versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Choosing $p_\\theta(\\z)$\n",
    "\n",
    "So what distribution should we use for the prior $p_\\theta(\\z)$ ?\n",
    "\n",
    "One important consideration is that, since we learn by SGD, we need to be able to differentiate.\n",
    "\n",
    "Another consideration is that the functional form of the distribution (i.e., an empirical distribution doesn't have a closed functional form) may simplify the math (e.g. normal).\n",
    "\n",
    "To force the tractability of $q_\\phi(\\z|\\x)$ we\n",
    "will define *prior distribution* $p_\\theta(\\z)$ to have a tractable, closed form (often a normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVIedxZelBZN",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss function: discussion\n",
    "\n",
    "**TO DO: Expand**\n",
    "\n",
    "The reconstruction loss should be familiar: it tries to force the decoded output to be \"close\" to\n",
    "the input.\n",
    "\n",
    "What would happen if we omitted the KL divergence constraint $\\loss_D$ from $\\loss$ ?\n",
    "\n",
    "Without it, the model could theoretically learn encodings $q_\\phi(\\z|\\x)$ whose\n",
    "distribution had near zero variance.\n",
    "\n",
    "This would collapse the VAE into the vanilla AE.\n",
    "\n",
    "So by choosing $p_\\theta(\\z)$ with a non-zero variance, we force the encoder to be probabilistic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variational inference\n",
    "\n",
    "**TO DO: NEEDS WORK, or omit.  Really only need to discuss ELBO, if anything**\n",
    "\n",
    "The cost/loss needs to be simplified quite a bit.\n",
    "\n",
    "This is beyond the scope of this talk but we refer the reader to\n",
    "[VAE tutorial](https://arxiv.org/pdf/1606.05908.pdf) (Also recommended by Geron in footnote 7, Chapt 15)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To summarize\n",
    "- we still have an intractable term (appears as another $\\KL$ divergence after re-writing cost/loss\n",
    "    - this term appears as an additive term\n",
    "    - by definition of $\\KL$, it is positive\n",
    "- so we can't evaluate the full cost/loss function\n",
    "    - but, ignoring the intractable positive part, the remainder is a *lower bound* on the cost/loss\n",
    "        - so we optimize the lower bound\n",
    "        - called the *ELBO* term (LB is lower bound)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnFvZdJ1sV_e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Re-parameterization trick\n",
    "\n",
    "There is still one more problem for training:\n",
    "- sampling $\\hat{\\z}  \\sim  q_\\phi(\\z|\\x)$\n",
    "\n",
    "This is not a problem in the forward pass.\n",
    "\n",
    "Optimization via back propogation requires the ability to take derivatives of the loss wrt the trainable parameters.\n",
    "\n",
    "How do we take the derivative of a node involving a random choice ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnFvZdJ1sV_e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The trick is to re-express $z$:\n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "\\mathbf{z}  & = & \\mathbf{\\mu} + \\mathbf{\\sigma} \\mathbf{\\epsilon} \\\\\n",
    "\\mathbf{\\epsilon} & \\sim & \\hat{p}(\\mathbf{z}) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is, we obtain $z$ \n",
    "- By sampling an $\\epsilon$ from the constraining distribution $\\hat{p}(z)$\n",
    "- Scaling the random $\\epsilon$ by variable (function of $\\x$) $\\sigma$ and adding variable (function of $\\x$) $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnFvZdJ1sV_e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We still can't take derivatives of $L_R$ with respect to $\\epsilon$, but we don't need to !\n",
    "\n",
    "We only need to take derivates of $L_R$ with respect to $\\phi, \\theta, \\mu, \\sigma$, which we can do.\n",
    "\n",
    "In evaluating derivatives, the $\\epsilon$ that appears in the result (e.g., derivative wrt $\\sigma$) can be treated as a constant.\n",
    "\n",
    "- For a particular example, we can remember the  drawn $\\epsilon$ in the forward pass and use it in the backward pass ?\n",
    "  - but over a batch, the expected value over the drawn $\\epsilon$ should be $E( \\hat{p}(z) )$ (which is $0$ is we constrain $\\hat{p}$ to be $0$ centered)\n",
    "  \n",
    "$$\n",
    "\\begin{array}[llll] \\\\\n",
    "L_D(\\phi, \\mathbf{\\mu}, \\mathbf{\\sigma}, \\mathbf{x}) & = & D_{\\text{KL}} \\left(  q_\\phi(\\z|\\x), \\hat{p}_{\\mathbf{\\mu}, \\mathbf{\\sigma}}(\\z) \\right) \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Reparameterization trick</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Reparameterization_trick.jpg\" width=800></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Autoencoders_and_Generative_Models.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
